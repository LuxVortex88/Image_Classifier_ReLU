{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUzNX0ePTxkYQL4NmZixCL"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTZ9vi_ZCtZf",
        "outputId": "e04f627c-094b-4fb6-d6e7-d97577c99413"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m827.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 6.06MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 160kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.52MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.04MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch 1 [0/60000]  Loss: 2.3072\n",
            "Train Epoch 1 [6400/60000]  Loss: 0.2407\n",
            "Train Epoch 1 [12800/60000]  Loss: 0.2161\n",
            "Train Epoch 1 [19200/60000]  Loss: 0.0507\n",
            "Train Epoch 1 [25600/60000]  Loss: 0.0885\n",
            "Train Epoch 1 [32000/60000]  Loss: 0.1983\n",
            "Train Epoch 1 [38400/60000]  Loss: 0.0096\n",
            "Train Epoch 1 [44800/60000]  Loss: 0.0279\n",
            "Train Epoch 1 [51200/60000]  Loss: 0.1487\n",
            "Train Epoch 1 [57600/60000]  Loss: 0.0726\n",
            "==> Epoch 1 Average Loss: 0.1229\n",
            "==> Test set: Average loss: 0.0466, Accuracy: 9850/10000 (98.50%)\n",
            "Train Epoch 2 [0/60000]  Loss: 0.0886\n",
            "Train Epoch 2 [6400/60000]  Loss: 0.0699\n",
            "Train Epoch 2 [12800/60000]  Loss: 0.0663\n",
            "Train Epoch 2 [19200/60000]  Loss: 0.0507\n",
            "Train Epoch 2 [25600/60000]  Loss: 0.0142\n",
            "Train Epoch 2 [32000/60000]  Loss: 0.0047\n",
            "Train Epoch 2 [38400/60000]  Loss: 0.0110\n",
            "Train Epoch 2 [44800/60000]  Loss: 0.0092\n",
            "Train Epoch 2 [51200/60000]  Loss: 0.0946\n",
            "Train Epoch 2 [57600/60000]  Loss: 0.0346\n",
            "==> Epoch 2 Average Loss: 0.0417\n",
            "==> Test set: Average loss: 0.0341, Accuracy: 9886/10000 (98.86%)\n",
            "Train Epoch 3 [0/60000]  Loss: 0.0400\n",
            "Train Epoch 3 [6400/60000]  Loss: 0.0014\n",
            "Train Epoch 3 [12800/60000]  Loss: 0.0107\n",
            "Train Epoch 3 [19200/60000]  Loss: 0.0228\n",
            "Train Epoch 3 [25600/60000]  Loss: 0.0023\n",
            "Train Epoch 3 [32000/60000]  Loss: 0.0024\n",
            "Train Epoch 3 [38400/60000]  Loss: 0.0565\n",
            "Train Epoch 3 [44800/60000]  Loss: 0.0116\n",
            "Train Epoch 3 [51200/60000]  Loss: 0.0076\n",
            "Train Epoch 3 [57600/60000]  Loss: 0.0126\n",
            "==> Epoch 3 Average Loss: 0.0263\n",
            "==> Test set: Average loss: 0.0430, Accuracy: 9876/10000 (98.76%)\n",
            "Train Epoch 4 [0/60000]  Loss: 0.0379\n",
            "Train Epoch 4 [6400/60000]  Loss: 0.0006\n",
            "Train Epoch 4 [12800/60000]  Loss: 0.0083\n",
            "Train Epoch 4 [19200/60000]  Loss: 0.0042\n",
            "Train Epoch 4 [25600/60000]  Loss: 0.1319\n",
            "Train Epoch 4 [32000/60000]  Loss: 0.0016\n",
            "Train Epoch 4 [38400/60000]  Loss: 0.0013\n",
            "Train Epoch 4 [44800/60000]  Loss: 0.0017\n",
            "Train Epoch 4 [51200/60000]  Loss: 0.0705\n",
            "Train Epoch 4 [57600/60000]  Loss: 0.0066\n",
            "==> Epoch 4 Average Loss: 0.0179\n",
            "==> Test set: Average loss: 0.0486, Accuracy: 9854/10000 (98.54%)\n",
            "Train Epoch 5 [0/60000]  Loss: 0.0665\n",
            "Train Epoch 5 [6400/60000]  Loss: 0.0021\n",
            "Train Epoch 5 [12800/60000]  Loss: 0.0002\n",
            "Train Epoch 5 [19200/60000]  Loss: 0.0061\n",
            "Train Epoch 5 [25600/60000]  Loss: 0.0261\n",
            "Train Epoch 5 [32000/60000]  Loss: 0.0007\n",
            "Train Epoch 5 [38400/60000]  Loss: 0.0043\n",
            "Train Epoch 5 [44800/60000]  Loss: 0.0016\n",
            "Train Epoch 5 [51200/60000]  Loss: 0.0511\n",
            "Train Epoch 5 [57600/60000]  Loss: 0.0061\n",
            "==> Epoch 5 Average Loss: 0.0142\n",
            "==> Test set: Average loss: 0.0388, Accuracy: 9903/10000 (99.03%)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision --quiet\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Check for GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Data Loading & Transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
        "\n",
        "# Define CNN Model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.fc1 = nn.Linear(9216, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = CNN().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training Function\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f'Train Epoch {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)}]  Loss: {loss.item():.4f}')\n",
        "    print(f'==> Epoch {epoch} Average Loss: {total_loss / len(train_loader):.4f}')\n",
        "\n",
        "# Testing Function\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    loss_total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            loss_total += F.cross_entropy(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1)\n",
        "            correct += pred.eq(target).sum().item()\n",
        "\n",
        "    loss_avg = loss_total / len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    print(f'==> Test set: Average loss: {loss_avg:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)')\n",
        "\n",
        "# Run Training Loop\n",
        "for epoch in range(1, 6):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ]
    }
  ]
}